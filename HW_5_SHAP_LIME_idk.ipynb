{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569bf2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the single model file fitted on 9:4:6 split data\n",
    "\n",
    "# %run -i \"C:/Users/LL/Desktop/RPI/24_Spring/AMLF/HW_5_SHAP_LIME/Enet_NeuralNet_v2.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/users/LL/Documents/GitHub/AMLF_projects/data.csv')\n",
    "\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "# According to note 30: \"Therefore, to predict returns at month t+1, we use most recent monthly characteristics at the end of month t.\" <br>\n",
    "# Hence, **shift return t+1 to serve as response: r(t+1)**.\n",
    "\n",
    "df['r(t+1)'] = df.groupby('permno')['return'].shift(-1)\n",
    "\n",
    "### handle missing data\n",
    "\n",
    "# According to note 30 (bottom of p 2248): \"Another issue is missing characteristics, which we replace with the cross-sectional median at each month for each stock, respectively.\" <br>\n",
    "# Hence, calculate monthly cross-sectional median for features: **'mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr'**.\n",
    "\n",
    "df_filled = df.copy()\n",
    "for feature in ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']:\n",
    "    df_filled[feature] = df_filled.groupby('Date')[feature].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df_filled.isna().sum()\n",
    "\n",
    "df.loc[:, ['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']] = df_filled.loc[:,['mom1m', 'mom12m', 'chmom', 'mom36m', 'turn', 'dolvol', 'idiovol', 'beta', 'betasq', 'ep', 'sp', 'agr', 'nincr']]\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the datetime column as index\n",
    "df.set_index('Date', inplace=True, drop = True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "\n",
    "permno = df['permno'].reset_index(drop = True)\n",
    "\n",
    "df_scaled['permno'] = permno\n",
    "\n",
    "df_scaled.index = df.index\n",
    "\n",
    "df_scaled_2 = df_scaled.drop(columns = [ 'permno', 'return'])\n",
    "\n",
    "\n",
    "### split data\n",
    "\n",
    "##split training, validation, and testing datasets\n",
    "\n",
    "#training : validation : testing = 6 yr : 4yr : 9 yr <br>\n",
    "#Also drop the first and last month due to the absence of r(t+1) and return(t-1)\n",
    "\n",
    "training = df_scaled_2[:'2007-01-01'].dropna()\n",
    "validation = df_scaled_2['2007-01-01':'2011-01-01']\n",
    "testing = df_scaled_2['2011-01-01':].dropna()\n",
    "\n",
    "training_combined = df_scaled_2[:'2011-01-01'].dropna()\n",
    "\n",
    "\n",
    "##separate X and y\n",
    "\n",
    "X_train = training.drop(columns = ['r(t+1)'])\n",
    "y_train = training['r(t+1)']\n",
    "\n",
    "X_val = validation.drop(columns = ['r(t+1)'])\n",
    "y_val = validation['r(t+1)']\n",
    "\n",
    "X_test = testing.drop(columns = ['r(t+1)'])\n",
    "y_test = testing['r(t+1)']\n",
    "\n",
    "X_train_combined = training_combined.drop(columns = ['r(t+1)'])\n",
    "y_train_combined = training_combined['r(t+1)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876eb7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NN\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "\n",
    "# convert dataframes to numpy array\n",
    "\n",
    "X_train_nn = np.asarray(X_train.values)\n",
    "y_train_nn = np.asarray(y_train.values)\n",
    "\n",
    "X_val_nn = np.asarray(X_val.values)\n",
    "y_val_nn = np.asarray(y_val.values)\n",
    "\n",
    "X_test_nn = np.asarray(X_test.values)\n",
    "y_test_nn = np.asarray(y_test.values)\n",
    "\n",
    "X_train_combined_nn = np.asarray(X_train_combined.values)\n",
    "y_train_combined_nn = np.asarray(y_train_combined.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125702cb",
   "metadata": {},
   "source": [
    "## model\n",
    "{'epoch': 100, 'learning_rate': 0.001, 'batch_size': 2500} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3cc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "import random\n",
    "\n",
    "def r2_score_wo_demeaning_nn(y_true, y_pred):\n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - 0))\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bab0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.021094502635160946"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_nn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52288b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c58ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\LL\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_seed = 77\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# nn3 model\n",
    "\n",
    "model_nn3 = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_dim=20),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(8, activation='relu'),\n",
    "            layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "\n",
    "model_nn3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss='mean_squared_error', metrics=r2_score_wo_demeaning_nn)\n",
    "\n",
    "history = model_nn3.fit(X_train_combined_nn, y_train_combined_nn, epochs=100, batch_size=2500,\n",
    "                            validation_data=(X_test_nn, y_test_nn), verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11402f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4578568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0419025793671608"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch_metric = history.history['val_r2_score_wo_demeaning_nn'][-1]\n",
    "\n",
    "last_epoch_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7aeab",
   "metadata": {},
   "source": [
    "# HW 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d994d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e79bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled_2.dropna().drop(columns = ['r(t+1)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd360f8",
   "metadata": {},
   "source": [
    "sort data:<br>\n",
    "by dolvol<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a770190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.sort_values(by=[\"dolvol\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078431c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function min> -4.749755120876968\n",
      "<built-in function max> 1.9821470349015913\n"
     ]
    }
   ],
   "source": [
    "print(min, X['dolvol'].min())\n",
    "print(max, X['dolvol'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c23fe",
   "metadata": {},
   "source": [
    "create 5 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50daa834",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list()\n",
    "end = 0\n",
    "start = 0\n",
    "size = int(113000/5)\n",
    "\n",
    "for i in range(5):\n",
    "    end = end + size\n",
    "    tmp = X.iloc[start:end,:]\n",
    "    bins.append(tmp)\n",
    "    start = start + size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b735b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22600\n",
      "-0.9093693679629887\n",
      "-4.749755120876968\n",
      "------\n",
      "22600\n",
      "-0.17561548513264147\n",
      "-0.9093631545240612\n",
      "------\n",
      "22600\n",
      "0.35791880105283025\n",
      "-0.1756097149360904\n",
      "------\n",
      "22600\n",
      "0.8891905133723533\n",
      "0.3579209861792339\n",
      "------\n",
      "22600\n",
      "1.9821470349015913\n",
      "0.8892152394947396\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# to make sure bins are correct\n",
    "\n",
    "for item in bins:\n",
    "    print(len(item))\n",
    "    print(item['dolvol'].max())\n",
    "    print(item['dolvol'].min())\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05388b03",
   "metadata": {},
   "source": [
    "## LIME\n",
    "features of interest: dolvol, baspred, sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5feadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d9268fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mom1m',\n",
       " 'mom12m',\n",
       " 'chmom',\n",
       " 'indmom',\n",
       " 'mom36m',\n",
       " 'turn',\n",
       " 'mvel1',\n",
       " 'dolvol',\n",
       " 'ill',\n",
       " 'zerotrade',\n",
       " 'baspread',\n",
       " 'retvol',\n",
       " 'idiovol',\n",
       " 'beta',\n",
       " 'betasq',\n",
       " 'ep',\n",
       " 'sp',\n",
       " 'agr',\n",
       " 'nincr',\n",
       " 'return(t-1)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "952d32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexs\n",
    "idx_1 = [random.randint(0, 22599) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38b0a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec238f",
   "metadata": {},
   "source": [
    "**explainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e7530d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_np, feature_names=X.columns.tolist(), verbose=True, mode='regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83182331",
   "metadata": {},
   "source": [
    "**explains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22bc7c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# idx = idx_1[0]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39marray(bins[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx,])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "# idx = idx_1[0]\n",
    "np.array(bins[0].iloc[idx,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains_1 = list()\n",
    "for i in range(10):\n",
    "    idx = idx_1[i]\n",
    "    exp = explainer.explain_instance(np.array(bins[0].iloc[idx,]), model.predict, num_features=5)\n",
    "    explains_1.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cffff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains_2 = list()\n",
    "for i in range(10):\n",
    "    idx = idx_1[i]          \n",
    "    exp = explainer.explain_instance(np.array(bins[1].iloc[idx,]), model.predict, num_features=5)\n",
    "    explains_2.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains_3 = list()\n",
    "for i in range(10):\n",
    "    idx = idx_1[i]\n",
    "    exp = explainer.explain_instance(np.array(bins[2].iloc[idx,]), model.predict, num_features=5)\n",
    "    explains_3.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains_4 = list()\n",
    "for i in range(10):\n",
    "    idx = idx_1[i]\n",
    "    exp = explainer.explain_instance(np.array(bins[3].iloc[idx,]), model.predict, num_features=5)\n",
    "    explains_4.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307da008",
   "metadata": {},
   "outputs": [],
   "source": [
    "explains_5 = list()\n",
    "for i in range(10):\n",
    "    idx = idx_1[i]\n",
    "    exp = explainer.explain_instance(np.array(bins[4].iloc[idx,]), model.predict, num_features=5)\n",
    "    explains_5.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6663369",
   "metadata": {},
   "source": [
    "**interpret results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4be835",
   "metadata": {},
   "source": [
    "**bin 1**<br>\n",
    "For bin 1, mom12m > .34, mom36m > .27, -0.03 < mom1m <= 0.43, retvol > 0.29, nincr <= -0.76, ill > -0.11 have negative impact on return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    explains_1[i].show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3b4f6",
   "metadata": {},
   "source": [
    "**bin 2**<br>\n",
    "For bin 2, turn > 0.25, -0.70 < idiovol <= -0.27, retvol > 0.29, mom1m > -0.03, turn > 0.25, mom36m > 0.27, chmom <= -0.45, ep <= 0.09, mom12m > 0.34 have negative impact on return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7197033",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    explains_2[i].show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e034280",
   "metadata": {},
   "source": [
    "**bin 3**<br>\n",
    "For bin 3, idiovol <= -0.27, mom36m > 0.27, return(t-1) <= -0.44, mom12m > 0.34, chmom <= -0.01, nincr <= -0.76, betasq > 0.27, -0.03 < mom1m, turn > 0.25, return(t-1) <= -0.44, -0.45 < sp <= -0.31 have negative impact on return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    explains_3[i].show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab56ff",
   "metadata": {},
   "source": [
    "**bin 4**<br>\n",
    "For bin 4, mom36m > 0.27, idiovol <= -0.27, return(t-1) <= -0.44, mom12m > 0.34, mvel1 > -0.17, -0.58 < indmom <= 0.46, turn > 0.25, retvol > 0.29, dolvol > 0.74, -0.01 < chmom <= 0.42, -0.03 < mom1m <= 0.43, nincr <= -0.76 have negative impact on return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62174ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    explains_4[i].show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68147377",
   "metadata": {},
   "source": [
    "**bin 5**<br>\n",
    "For bin 5, idiovol <= -0.27, mvel1 > -0.17, return(t-1) <= -0.44, dolvol > 0.74, mom1m > -0.03, retvol > 0.29, ep <= 0.09, turn > 0.25, mom12m > 0.34, mom36m > 0.27, chmom <= -0.45,  have negative impact on return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5351ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    explains_5[i].show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed4748",
   "metadata": {},
   "source": [
    "## Shapley\n",
    "features of interest: dolvol(8), baspred(11), sp(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea26c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M = 10  # the number of random samples to calculate marginal contribution from\n",
    "n_features = len(X.columns)\n",
    "feature_idxs = [7, 10, 16]\n",
    "sample_to_explain = list()\n",
    "shapley_value_all = list()\n",
    "\n",
    "\n",
    "for df in bins:  # for each bin\n",
    "    samplex = df.sample(10)\n",
    "    sample_to_explain.append(samplex)\n",
    "    xarray = samplex.values\n",
    "    \n",
    "    for i in range(10):\n",
    "        x = xarray[i]\n",
    "        print(\"selected instance: \", x)# instance of interest\n",
    "        shapley_values = []\n",
    "\n",
    "        for i in range(3):   # for each feature of interest\n",
    "            x_idx = [7, 10, 16]\n",
    "            marg_contri_feature = []\n",
    "\n",
    "            feature_of_interest = feature_idxs[i]\n",
    "            print(\"Index of feature of interest: \", feature_of_interest)\n",
    "            x_idx.remove(feature_of_interest)\n",
    "\n",
    "            all_combinations = []  # all coalitions of features minus the feature of interest\n",
    "            for r in range(1, len(x_idx) + 1):\n",
    "                combinations_of_length_r = list(combinations(x_idx, r))\n",
    "                all_combinations.extend(combinations_of_length_r)\n",
    "\n",
    "            for coalition in all_combinations:  # for each coalition\n",
    "                coalition = list(coalition)\n",
    "                print('the current coalition: ', coalition)\n",
    "                weight = math.factorial(len(coalition)) * math.factorial(n_features - len(coalition)-1)/ math.factorial(n_features)\n",
    "                print(\"weight of this coalition: \", weight)\n",
    "\n",
    "                marg_contri_coalition = []  # marginal contributions of this coalition\n",
    "\n",
    "                for _ in range(M):\n",
    "                    z = df.sample(1).values[0]  # random select sample    \n",
    "\n",
    "                    # construct two new instances\n",
    "                    x_orig = np.array([x[i] if i in coalition + [feature_of_interest] else z[i] for i in range(n_features)])\n",
    "                    x_rando = np.array([x[i] if i in coalition else z[i] for i in range(n_features)])             \n",
    "\n",
    "                    # calculate marginal contribution\n",
    "                    marginal_contribution = model.predict(x_orig.reshape(1, -1))[0][0] - model.predict(x_rando.reshape(1, -1))[0][0]\n",
    "                    marg_contri_coalition.append(marginal_contribution)\n",
    "\n",
    "                sigma_j = sum(marg_contri_coalition) / len(marg_contri_coalition)\n",
    "                shapley_coalition = sigma_j*weight  # for one coaltion examined for feature of interest\n",
    "                marg_contri_feature.append(shapley_coalition)\n",
    "\n",
    "            shapley_j = sum(marg_contri_feature)  # shapley value of feature j\n",
    "            shapley_values.append(shapley_j)\n",
    "\n",
    "            print(\"feature of interest: \", feature_of_interest)\n",
    "            print(\"shapley value of this feature: \", shapley_j)\n",
    "            print('--------')\n",
    "            print('--------')\n",
    "        shapley_value_all.append(shapley_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample = pd.concat([sample_to_explain[0], sample_to_explain[1]], ignore_index=True)\n",
    "all_sample = pd.concat([all_sample, sample_to_explain[2]], ignore_index=True)\n",
    "all_sample = pd.concat([all_sample, sample_to_explain[3]], ignore_index=True)\n",
    "all_sample = pd.concat([all_sample, sample_to_explain[4]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c795b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapleydf = pd.DataFrame(shapley_value_all, columns = ['feature: dolvol', 'feature: baspred', 'feature: sp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_mtx = pd.concat([all_sample, shapleydf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd8267",
   "metadata": {},
   "source": [
    "### shapley value matrix with all samples examined\n",
    "bin1: 0-9<br>\n",
    "bin2: 10-19<br>\n",
    "bin3: 20-29<br>\n",
    "bin4: 30-39<br>\n",
    "bin5: 40-49<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc855d",
   "metadata": {},
   "source": [
    "**bin 1**<br>\n",
    "dolvol generally has a positive impact on return prediction, baspred and sp have negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1_shap = shapley_mtx.iloc[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1_shap.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef98434",
   "metadata": {},
   "source": [
    "**bin 2**<br>\n",
    "sp generally has a positive impact on return prediction, baspred and dolvol have negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin2_shap = shapley_mtx.iloc[10:20,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ec6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin2_shap.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe467f",
   "metadata": {},
   "source": [
    "**bin 3**<br>\n",
    "dolvol generally has a positive impact on return prediction, baspred and sp have negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin3_shap = shapley_mtx.iloc[20:30,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin3_shap.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39bc90",
   "metadata": {},
   "source": [
    "**bin 4**<br>\n",
    "baspred and dolvol generally has a positive impact on return prediction, sp have negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin4_shap = shapley_mtx.iloc[30:40,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin4_shap.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea31c4",
   "metadata": {},
   "source": [
    "**bin 5**<br>\n",
    "sp and dolvol generally has a positive impact on return prediction, baspred have negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin5_shap = shapley_mtx.iloc[40:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b90cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin5_shap.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616bf357",
   "metadata": {},
   "source": [
    "**overall**<br>\n",
    "Overall, dolvol have a positive impact on return predictions, baspred and sp have negative impact but the standard deviation are larger, indicating different local impacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8fcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_mtx.loc[:,['feature: dolvol', 'feature: baspred', 'feature: sp']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e648b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
